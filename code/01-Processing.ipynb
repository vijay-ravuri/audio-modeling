{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "PATH = os.getenv('AUDIO_PATH') # Folder where FMA data is unzipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the process of extracting the relevant track info along with computing our mel-spectograms for each song and storing them for use in later notebooks. An explanation of what a mel-spectogram is and why it is necessary can be found in the [EDA](./02-EDA.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the exact directory mp3s are housed in\n",
    "audio_PATH = PATH + \"fma_small/\"\n",
    "\n",
    "\n",
    "# Create lists to hold our data\n",
    "audio = []\n",
    "track_id = []\n",
    "\n",
    "\n",
    "# These 6 files need to be skipped due to incomplete data \n",
    "# See: https://github.com/mdeff/fma/wiki#excerpts-shorter-than-30s-and-erroneous-audio-length-metadata\n",
    "bad_files = [\n",
    "    '098/098565.mp3',\n",
    "    '098/098567.mp3',\n",
    "    '098/098569.mp3',\n",
    "    '099/099134.mp3',\n",
    "    '108/108925.mp3',\n",
    "    '133/133297.mp3'\n",
    "]\n",
    "\n",
    "# Iterate through each item in the directory\n",
    "for item in os.listdir(audio_PATH):\n",
    "    # Check that the item isn't a metadata file\n",
    "    if 'check' not in item and '.txt' not in item:\n",
    "        # Iterate through contents of the folder\n",
    "        for file in os.listdir(audio_PATH + item):\n",
    "            # Skip incomplete songs\n",
    "            if item + '/' + file in bad_files:\n",
    "                continue\n",
    "            # Create local filepath and grab track id\n",
    "            track_id.append(item + '/' + file)\n",
    "            file_path = audio_PATH + track_id[-1]\n",
    "\n",
    "            # Read song in using librosa\n",
    "            song, sr = librosa.load(file_path)\n",
    "\n",
    "            # Compute then rescale melspectogram into decibels\n",
    "            mel = librosa.power_to_db(librosa.feature.melspectrogram(y = song, sr = sr)).T[:1291]\n",
    "\n",
    "            # Append mel-spectogram into list\n",
    "            audio.append(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for raw_audio data\n",
    "raw_data = pd.Series(\n",
    "    audio, \n",
    "    index = pd.Series(\n",
    "        [int(id[-10:-4]) for id in track_id]\n",
    "        ), \n",
    "    name = 'audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in track data\n",
    "# Header is necessary due to the structure of the CSV\n",
    "df = pd.read_csv(PATH + \"fma_metadata/tracks.csv\", index_col=0, header=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracks file provided is composed of multiple dataframes which need to be called and handled separately. We chose to sequentially merge our data into exactly the info we want for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the relevant parts of each sub-dataframe\n",
    "artist_album = pd.merge(\n",
    "    df['artist'],\n",
    "    df['album'],\n",
    "    how = 'inner',\n",
    "    left_index = True,\n",
    "    right_index = True\n",
    ").rename(\n",
    "    {\n",
    "        'name' : 'name',\n",
    "        'title' : 'album'\n",
    "    },\n",
    "    axis = 1\n",
    ")[['name', 'album']] # Only need artist name and album here\n",
    "\n",
    "\n",
    "# Gather only the songs in the 'small' subset\n",
    "# 'set' here refers to the pre-defined train-test splits\n",
    "genre_artists = pd.merge(\n",
    "    df['set'][df['set']['subset'] == 'small'],\n",
    "    artist_album,\n",
    "    how = 'left',\n",
    "    left_index = True,\n",
    "    right_index = True\n",
    ")\n",
    "\n",
    "# Merge artist data back into the track info \n",
    "# Select only relevant columns\n",
    "tracks = pd.merge(\n",
    "    df['track'],\n",
    "    genre_artists,\n",
    "    how = 'inner',\n",
    "    left_index = True,\n",
    "    right_index = True\n",
    ")[['title', 'name', 'album', 'genre_top', 'split']]\n",
    "\n",
    "\n",
    "# Filter out incomplete rows and export to csv\n",
    "indices = [int(file[-10:-4]) for file in bad_files]\n",
    "tracks.loc[~tracks.index.isin(indices), ].to_csv('../data/tracks_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the individual mel-spectogram for each song\n",
    "# Using numpy's save feature because our data has issues being stored as a csv through pandas\n",
    "for idx, data in zip(raw_data.index, raw_data.values):\n",
    "    np.save('../data/audio' + str(idx), data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
